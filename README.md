# SAWO-NN repository

Welcome to the SAWO-NN repository on Github. This code is considered supplementary material for a journal paper currently under review. This README describes all the moving parts of this project, how to install the project onto your Google Drive, and how to run the project using Google Colaboratory.

## Description
- **control** folder: This folder contains JSON files, used to enable the parallelizability of grammatical evolution. The Controller notebook writes to these files before each generation. The Runner notebooks read this information and evaluate population members, storing their results in these files. The Controller notebook then reads the evaluations, and uses them to create the next generation, and so on.
- **datasets** folder: This folder contains pre-processed input and target NumPy arrays for each of the 12 datasets. A note here that the dataset IDs are slightly different as to in the paper, as described in the table below. Therefore, to reproduce results for a particular dataset ID from the paper, please use the corresponding code ID.

| Paper ID | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Code ID | 1 | 2 | 3 | 5 | 6 | 7 | 8 | 10 | 11 | 12 | 4 | 9 |

- **runs** folder: This folder will contain JSON files generated from every full run of the grammatical evolution, created by the Controller notebook.
- **samples** folder: This folder will contain JSON files generated from every generated sample, created by the SampleComparison notebook.
- **Architecture.py**: Instances of this Python class are instantiated using a shorthand-architecture-array, which dynamically builds the corresponding Tensorflow architecture, as per the architecture construction rules of the paper. This class also provides a method to calculate the error currently produced by the built architecture on some inputs and targets.
- **Controller.ipynb**: This Jupyter notebook controls the flow of the grammatical evolution, as well as gives instructions to the Runner notebooks. It generates the initial population, and repeatedly does the following: assigns the population amongst the Runner notebooks, waits for them to evaluate their assigned members, captures the evaluations, and performs selection and application of genetic operators to create a new population. While doing all of this, it captures summary information about fitness values, genetic diversity and genetic operator effectiveness. Finally, it saves all this information and the best found members over the run into a JSON file, stored in the **runs** folder.
- **Member.py**: This Python class calls the necessary functions of **RuleSet.py** to convert a bitstring chromosome into the information needed to instantiate a SAWO-NN through the grammar, and instantiates it. It then performs the repeated training of the SAWO-NN on provides inputs and targets, calculating and returning fitness based on the average generalization abilities after these trainings.
- **Node.py**: This Python class is used in determining which sets-of-weights need to be maintained for a SAWO-NN based on its chromosome. It keeps reference of edges from it to other nodes, and can find all nodes reachable from it by directed walks.
- **Rule.py**: This Python class is used to logically store all possible outputs from one symbol of the grammar, and is instantiated based on the grammar provided.
- **RuleSet.py**: This Python class takes a text file containing grammar rules as input, parses the file, and generates a full set of grammar rules, each an instance of **Rule.py**. Using this full set of rules, it can take input bitstring codons, use these bitstring codons to choose rule options as per the technique of grammatical evolution, and return the instance of the grammar correlating to that input. 
- **Runner_1...4.ipynb**: These Jupyter notebooks perform evaluation of population members assigned to them by the Controller notebook. This is done by instantantiating an instance of **Member.py** for every bitstring chromosome it has been assigned, calling the fitness function of this class, and storing these fitnesses into the control files for the Controller notebook to read. There are 4 notebooks because Google Colab allows for a maximum of 5 workbooks to be running concurrently. 
- **SampleComparison.ipynb**: This Jupyter notebook is used to generate the performance sample for a particular bitstring chromosome (and the SAWO-NN it describes) on a particular dataset. The best chromosomes for each dataset are provided, so their performance samples can be re-generated and saved in the **samples** folder in JSON format, however, their pre-computed performance samples are also provided. Performance samples for the baseline models can also be generated, with the best learning rates found for each dataset also provided. Finally, the performance sample of the best SAWO-NN can be compared to the baseline model performance sample, for each dataset, to re-confirm the hypothesis testing results achieved.
- **SawoNN.py**: This Python class implements a SAWO-NN as described in the paper. To instantiate a SAWO-NN, information must be provided on layer sizes, the primary architecture, and each weight update equation. The needed weights and architectures can then be calculated. To train a SAWO-NN on some inputs and targets, the training process in the paper is followed. This class implements the vital function used to calculate the error derivative of any set-of-weights in any initialised architecture, thanks to some clever usage of Tensorflow's GradientTape and the **Architecture.py** class.
- **grammar.txt**: This text file contains the grammar rules specified in the paper, albeit with symbols linked to a single output replaced with that output, which avoids redundant codons without decreasing the possible search space. This file is read and parsed by the **RuleSet.py** class.

## Installation
